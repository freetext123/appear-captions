<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AppearCaptions | Pro Dynamic AI</title>
    <style>
        :root { --main: #ffa550; --bg: #121212; }
        body { background: var(--bg); color: white; font-family: sans-serif; text-align: center; padding: 10px; }
        .container { max-width: 450px; margin: auto; background: #1e1e1e; padding: 15px; border-radius: 15px; border: 2px solid #333; }
        #v-preview { width: 100%; border-radius: 10px; display: none; margin-top: 10px; border: 1px solid #444; }
        .btn { background: var(--main); color: black; padding: 15px; border-radius: 30px; border: none; font-weight: bold; width: 100%; cursor: pointer; margin-top: 15px; }
        #status { color: var(--main); font-size: 0.8rem; margin-top: 10px; font-weight: bold; }
        canvas { display: none; } /* Hidden, used for recording only */
    </style>
</head>
<body>

    <h1 style="color: var(--main);">AppearCaptions AI</h1>
    
    <div class="container">
        <input type="file" id="video-input" accept="video/*" style="display:none;">
        <button class="btn" onclick="document.getElementById('video-input').click()">UPLOAD VIDEO</button>
        
        <div id="status">Waiting for AI...</div>
        <video id="v-preview" muted playsinline></video>
        
        <button id="render-btn" class="btn" style="display:none;">GENERATE DYNAMIC VIDEO (10s)</button>
        <canvas id="render-canvas"></canvas>
    </div>

    <script type="module">
        import { pipeline } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.6.0';

        const videoInput = document.getElementById('video-input');
        const renderBtn = document.getElementById('render-btn');
        const status = document.getElementById('status');
        const player = document.getElementById('v-preview');
        const canvas = document.getElementById('render-canvas');
        const ctx = canvas.getContext('2d');

        let transcriber;
        let wordTimestamps = [];

        // 1. Init Professional AI
        async function init() {
            status.innerText = "â³ Loading AI Engine...";
            transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-tiny.en');
            status.innerText = "âœ… AI Ready! Upload Video.";
        }
        init();

        videoInput.onchange = async () => {
            const file = videoInput.files[0];
            if (!file) return;

            status.innerText = "ðŸŽ¤ Analyzing Speech & Timing...";
            player.src = URL.createObjectURL(file);
            player.style.display = "block";
            
            const audioContext = new AudioContext({ sampleRate: 16000 });
            const arrayBuffer = await file.arrayBuffer();
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            const audioData = audioBuffer.getChannelData(0).slice(0, 10 * 16000);

            // AI Magic: Get text WITH timestamps
            const result = await transcriber(audioData, { return_timestamps: 'word' });
            wordTimestamps = result.chunks; // This contains {text, timestamp: [start, end]}
            
            status.innerText = "âœ… AI Synced! Click to Download.";
            renderBtn.style.display = 'block';
        };

        renderBtn.onclick = () => {
            status.innerText = "ðŸš€ Recording Synchronized Video...";
            renderBtn.disabled = true;

            // FIX RATIO: Set canvas to match video exactly
            canvas.width = player.videoWidth;
            canvas.height = player.videoHeight;

            const stream = canvas.captureStream(30);
            const recorder = new MediaRecorder(stream, { mimeType: 'video/webm' });
            const chunks = [];

            recorder.ondataavailable = e => chunks.push(e.data);
            recorder.onstop = () => {
                const blob = new Blob(chunks, { type: 'video/webm' });
                const a = document.createElement('a');
                a.href = URL.createObjectURL(blob);
                a.download = "Appear_Dynamic_AI.webm";
                a.click();
                status.innerText = "âœ… Done! Pro Style Synced.";
                renderBtn.disabled = false;
            };

            player.currentTime = 0;
            player.play();
            recorder.start();

            const drawFrame = () => {
                if (player.currentTime >= 10 || player.ended) {
                    recorder.stop();
                    player.pause();
                    return;
                }
                
                // 1. Draw Video (No Stretch)
                ctx.drawImage(player, 0, 0, canvas.width, canvas.height);
                
                // 2. Find which word to show based on current time
                const currentTime = player.currentTime;
                const currentWord = wordTimestamps.find(w => 
                    currentTime >= w.timestamp[0] && currentTime <= w.timestamp[1]
                );

                if (currentWord) {
                    // Draw Dynamic Caption
                    ctx.fillStyle = "#ffa550"; // Pro Yellow
                    ctx.font = `bold ${canvas.height / 12}px sans-serif`;
                    ctx.textAlign = "center";
                    ctx.strokeStyle = "black";
                    ctx.lineWidth = 6;
                    
                    const text = currentWord.text.toUpperCase();
                    ctx.strokeText(text, canvas.width / 2, canvas.height * 0.8);
                    ctx.fillText(text, canvas.width / 2, canvas.height * 0.8);
                }
                
                requestAnimationFrame(drawFrame);
            };
            drawFrame();
        };
    </script>
</body>
</html>